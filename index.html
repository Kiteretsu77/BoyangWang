<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Boyang Wang</title>

  <meta name="author" content="Boyang Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"
    > -->
  <link rel="icon" href="figs/UMich-icon.png">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Pacifico">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Bio -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Boyang Wang</name>
                  </p>
                  <!-- bio -->
                  <p style="text-align:justify">
                    Hello!
                    This is Boyang Wang (ÁéãÂçöÊ¥ã).
                    I am a first-year PhD student at the University of Virginia, supervised by <a href="https://sites.google.com/site/zezhoucheng/"> Zezhou Cheng</a>.
                  </p>

                  <p style="text-align:justify"></p>
                    I graduated with a M.S. in Robotics and a B.S. in Computer Science from the University of Michigan (UMich).
                    At UMich, I worked with Prof. <a href="https://jjparkcv.github.io">JJ Park</a>, Prof. <a href="https://www.mmintlab.com/people/nima-fazeli/">Nima Fazeli</a>, 
                    Prof. <a href="https://kim.engin.umich.edu/">Hun-Seok Kim</a>, and Prof. <a href="https://web.eecs.umich.edu/~ocj/">Chad Jenkins</a>. 

                    During the summer of 2025, I interned at Shanghai AI Lab, working closely with <a href="https://sheldontsui.github.io/">Xudong Xu</a> on embodied AI department.
                  </p>

                  <p style="text-align:justify">
                    My research interests mainly lie in Generative Models (especially video) for General, Robotics, and Anime domains!
                  </p>
                  
                  <!-- <p style="text-align:justify"></p>
                    <span style="color: red;">I am actively looking for Intern Position Worldwide to start in this Summer related to Video/Image/3D Generation!</span> -->

                  <!-- links -->
                  <p style="text-align:center">
                    <a href="mailto:boyangwa@umich.edu">Email</a> &nbsp¬∑&nbsp
                    <a href="https://x.com/BoyangWang7">Twitter</a> &nbsp¬∑&nbsp
                    <a href="https://github.com/Kiteretsu77">Github</a> &nbsp¬∑&nbsp
                    <a href="https://scholar.google.com/citations?user=w7o4OYAAAAAJ&hl=en&oi=ao">Google Scholar</a>
                    <!-- &nbsp¬∑&nbsp -->
                  </p>
                </td>
                <!-- profile image -->
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="figs/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="figs/avatar.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- News -->
          <table
            style="width:100%; border:0px; border-spacing:0px; border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px; width:100%; vertical-align:middle">
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <li style="line-height:125%">
                      09/2025:
                      &#x1F389;
                      Frame In-N-Out is accepted by NeurIPS 2025! See you in San Diego!
                    </li>
                    <li style="line-height:125%">
                      08/2025:
                      &#129395;
                      Begin my journey as PhD student at the University of Virginia.
                    </li>
                    <li style="line-height:125%">
                      05/2025:
                      &#x1F389;
                      Frame In-N-Out: Unbounded Controllable Image-to-Video Generation is released on Arxiv.
                    </li>
                    <li style="line-height:125%">
                      02/2025:
                      &#x1F389;
                      One paper is accepted by CVPR 2025. See you in Nashville!
                    </li>
                    <li style="line-height:125%">
                      01/2025:
                      &#x1F389;
                      One paper is accepted by ICRA 2025. See you in Atlanta!
                    </li>
                    <li style="line-height:125%">
                      01/2025:
                      &#x1F389;
                      One paper is accepted by RA-L.
                    </li>
                    <li style="line-height:125%">
                      12/2024:
                      &#x1F389;
                      Graduated from University of Michigan as Master Degree.
                    </li>
                    <li style="line-height:125%">
                      08/2024:
                      &#x1F389;
                      Being selected as GSI for the EECS498 Computer Graphics and Generative Models.
                    </li>
                    <li style="line-height:125%">
                      07/2024:
                      &#x1F389;
                      This&That: Language-Gesture Controlled Video Generation for Robot Planning is released on Arxiv.
                    </li>
                    <li style="line-height:125%">
                      02/2024:
                      &#x1F389;
                      One paper is accepted by CVPR 2024.
                    </li>
                    <li style="line-height:125%">
                      10/2023:
                      &#x1F389;
                      One paper is accepted by WACV 2024.
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>


          
          <!-- Publications -->
          <br>
          <table
            style="width:100%; border:0px; border-spacing:0px; border-collapse:separate;margin-right:auto;margin-left:auto;padding-top: 15px;">
            <tbody>
              <tr>
                <td style="padding:0px 20px; width:100%; ">
                  <heading>Selected Publications</heading>
                  <p>(* indicates equal contribution)</p> 
                </td>
              </tr>
            </tbody>
          </table>
          

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top: -45px;">
            
            <tbody>
              


              <tr>

                 <td style="width:25%;" align="center">
                  <img src="figs/robovip.gif" style="border-style: none; padding-bottom: 25px;" width="225">
                </td>

                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle> Frame In-N-Out: Unbounded Controllable Image-to-Video Generation
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Boyang Wang *</strong>,
                  <a href="https://haoranzhangumich.github.io/">Haoran Zhang *</a>,
                  <a href="https://hishujie.github.io/">Shujie Zhang *</a>,
                  <a href="https://jinkun-hao.github.io/">Jinkun Hao</a>,
                  <a href="https://github.com/Luyitas">Mingda Jia</a>,
                  <a href="https://github.com/aopolin-lv">Qi Lv</a>,
                  <a href="https://myc634.github.io/yuchengmao/">Yucheng Mao</a>,
                  <a href="https://zhaoyanglyu.github.io/">Zhaoyang Lyu</a>,
                  <a href="https://zeng-jia.github.io/">Jia Zeng</a>,
                  <a href="https://sheldontsui.github.io/">Xudong Xu</a>,
                  <a href="https://oceanpang.github.io/">Jiangmiao Pang</a>


                  <!-- conference & date -->
                  <br>
                   In Submission
                  <br>
                  <!-- links -->
                  <a href="https://arxiv.org/abs/2601.05241">Paper</a>
                  ¬∑ <a href="https://robovip.github.io/RoboVIP/">Website</a>
                  ¬∑ <a href="https://github.com/RoboVIP/RoboVIP_VDM">Github</a>
                  <!-- ¬∑ <a href="https://huggingface.co/collections/uva-cv-lab/frame-in-n-out">HuggingFace</a> -->

                  <p> A multi-view inpainting-based video diffusion model with identity reference as conditions to augment robotics manipulation data in both simulation and real-world robot setup. </p>
                </td>
              </tr>




              
              <tr>

                <td style="width:30%;" align="center">
                  <img src="figs/FrameINO.gif" style="border-style: none; padding-bottom: 25px;" width="225">
                </td>

                <td width="80%" valign="middle">
                  <!-- heading -->
                  <papertitle> Frame In-N-Out: Unbounded Controllable Image-to-Video Generation
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Boyang Wang</strong>,
                  <a href="https://xuweiyichen.github.io/">Xuweiyi Chen</a>,
                  <a href="http://mgadelha.me/">Matheus Gadelha</a>,
                  <a href="https://sites.google.com/site/zezhoucheng/">Zezhou Cheng</a>
                  <!-- conference & date -->
                  <br>
                  NeurIPS 2025
                  <br>
                  <!-- links -->
                  <a href="https://arxiv.org/abs/2505.21491">Paper</a>
                  ¬∑ <a href="https://uva-computer-vision-lab.github.io/Frame-In-N-Out/">Website</a>
                  ¬∑ <a href="https://github.com/UVA-Computer-Vision-Lab/FrameINO">Github</a>
                  ¬∑ <a href="https://huggingface.co/collections/uva-cv-lab/frame-in-n-out">HuggingFace</a>

                  <p> First paper in Video Generation that studies Frame In and Frame Out cinematics effect, which is conditioned on First Frame Expanded Canvas, Text Prompt, Motion Trajectory and Identity Reference. </p>
                </td>

              </tr>
              


              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle;" align="center">
                  <img src="figs/sirdiff.gif" style="border-style: none; padding-bottom: 10px;" width="225">
                </td>
                <td width="75%" valign="middle" style="padding-top: 25px">
                  <!-- heading -->
                  <papertitle>Sparse Image Sets Restoration with Multi-View Diffusion Model
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <a href="https://myc634.github.io/yuchengmao/">Yucheng Mao *</a>,
                  <strong>Boyang Wang *</strong>,
                  <a href="https://nileshkulkarni.github.io">Nilesh Kulkarni</a>,
                  <a href="https://jjparkcv.github.io">Jeong Joon Park</a>
                  <br>
                    CVPR 2025
                  <br>
                  <a href="https://arxiv.org/abs/2503.14463">Paper</a>
                  ¬∑ <a href="https://myc634.github.io/sirdiff/">Website</a>

                  <p>Reconstruct a 3D scene with degraded image sets by Mutliview Diffusion Model.</p>
                </td>
              </tr>



              <tr>
                <td style="width:25%;" align="center">
                  <img src="figs/thisandthat.gif" style="border-style: none; padding-bottom: 25px; padding-top: 10px;" width="225">
                </td>
                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle>This&That: Language-Gesture Controlled Video Generation for Robot Planning
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Boyang Wang</strong>,
                  <a href="https://www.linkedin.com/in/niksridhar/">Nikhil Sridhar</a>,
                  <a href="https://cfeng16.github.io/">Chao Feng</a>,
                  <a href="https://mvandermerwe.github.io/">Mark Van der Merwe</a>,
                  <a href="https://fishbotics.com/">Adam Fishman</a>,
                  <a href="https://www.mmintlab.com/people/nima-fazeli/">Nima Fazeli</a>,
                  <a href="https://jjparkcv.github.io/">Jeong Joon Park</a>
                  <!-- conference & date -->
                  <br>
                  ICRA 2025
                  <br>
                  <!-- links -->
                  <a href="https://arxiv.org/abs/2407.05530?context=cs">Paper</a>
                  ¬∑ <a href="https://cfeng16.github.io/this-and-that/">Website</a>
                  ¬∑ <a href="https://github.com/Kiteretsu77/This_and_That_VDM">Github</a>
                  ¬∑ <a href="https://huggingface.co/spaces/HikariDawn/This-and-That">HuggingFace</a>

                  <p>First paper with Language & Gesture conditioned Video Generative Model for the robot action mentoring.</p>
                </td>
              </tr>

              <br>

              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle;padding-top: 25px;" align="center">
                  <img src="figs/APISR_fig.png" href="https://imgsli.com/Mjc3NTc1" style="border-style: none" width="225">
                </td>
                <td width="75%" valign="middle" style="padding-top: 25px">
                  <!-- heading -->
                  <papertitle>APISR: Anime Production Inspired Real-World Anime Super-Resolution
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Boyang Wang</strong>,
                  <a href="https://fredfyyang.github.io/">Fengyu Yang</a>,
                  <a href="https://xihangyu630.github.io/">Xihang Yu</a>,
                  <a >Chao Zhang</a>,
                  <a >Hanbin Zhao</a>
                  <!-- conference & date -->
                  <br>
                  CVPR 2024
                  <br>
                  <!-- links -->
                  <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Wang_APISR_Anime_Production_Inspired_Real-World_Anime_Super-Resolution_CVPR_2024_paper.html">Paper</a>
                  ¬∑ <a href="https://github.com/Kiteretsu77/APISR">Github</a>
                  ¬∑ <a href="https://huggingface.co/spaces/HikariDawn/APISR">HuggingFace</a>

                  <p>SOTA Anime Super-Resolution and Restoration.</p>
                </td>
              </tr>
              
              <br>

              <tr>
                <td style="padding:10px 20px; width:25%; vertical-align:middle; padding-top: 20px;" align="center">
                  <img src="figs/VCISR_fig.png" style="border-style: none" width="225" height="110">
                </td>
                <td width="75%" valign="middle" style="padding-top: 20px">
                  <!-- heading -->
                  <papertitle>VCISR: Blind Single Image Super-Resolution with Video Compression Synthetic Data
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Boyang Wang</strong>*,
                  <a >Bowen Liu</a>*,
                  <a >Shiyu Liu</a>*,
                  <a href="https://fredfyyang.github.io/">Fengyu Yang</a>
                  <!-- conference & date -->
                  <br>
                  WACV 2024
                  <br>  
                  <!-- links -->
                  <a href="https://arxiv.org/abs/2311.00996">Paper</a>
                  ¬∑ <a href="https://github.com/Kiteretsu77/VCISR-official">Github</a>

                   <p>First paper studying the Video Compression Degradation on Image Super-Resolution.</p>
                </td>
              </tr>


              

            </tbody>
          </table>

          <br>
          <br>

          <!-- Teaching -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Teaching Assistant Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <li style="line-height:125%">
                      <strong>Graduate Student Instructor (GSI)</strong>,
                      <a href="https://um-graphics.github.io/">EECS498: Computer Graphics and Generative Models</a>,
                      Fall 2024
                    </li>
                    <li style="line-height:125%">
                      <strong>Graduate Student Instructor (GSI)</strong>,
                      <a href="https://autorob.org/">EECS367/ROB380/ROB511: AutoRob</a>,
                      Winter 2024
                    </li>
                    <li style="line-height:125%">
                        <strong>Teaching Assistant (IA)</strong>,
                        <a href="https://autorob.org/">EECS367/ROB380/ROB511: AutoRob</a>,
                        Winter 2023 
                      </li>
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
          
          <br>
          <br>

          <!-- Intern -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Intern Work Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>

                    <li style="line-height:125%">
                      <strong>Research Intern</strong>,
                      <a> Shanghai AI Lab </a>,
                      05/2025 - 08/2025
                    </li>

                    <li style="line-height:125%">
                      <strong>Machine Learning Engineer</strong>,
                      <a> ByteDance </a>,
                      04/2022 - 08/2022
                    </li>
                    
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <br>
          <br>

          <!-- Award -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Award</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>

                    <li style="line-height:125%">
                      UVA Provost Fellowship
                    </li>

                    <li style="line-height:125%">
                      Conference Travel Award: NeurIPS2025
                    </li>
                    
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <br>
          <br>


          <!-- Something talked at the end -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Something want to share at the end</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <strong>I believe that the optimizer to the life is the faith one has.</strong>
                    
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
          

        </td>
      </tr>
  </table>

</body>

</html>
